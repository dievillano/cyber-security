{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6b9e77",
   "metadata": {},
   "source": [
    "# Bayesian Neural Network (BNN) models training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bdded0",
   "metadata": {},
   "source": [
    "Import necessary libraries for numerical computing, data manipulation, and probabilistic programming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf824c6-14e4-45f6-a90c-5221f4826f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, SVI, Trace_ELBO, init_to_mean\n",
    "from numpyro.infer.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Configure NumPyro to use two CPU devices for parallel execution\n",
    "numpyro.set_host_device_count(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1e412d",
   "metadata": {},
   "source": [
    "Load training dataset and separate features (X) and class labels (y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559309db-235e-48fd-a675-420b1550550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/interim/train.csv')  \n",
    "X = train.drop('label', axis=1)\n",
    "y = train['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14257469",
   "metadata": {},
   "source": [
    "Split dataset into training and validation sets with stratification to preserve label distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f877f6-8c3b-49b6-bd40-bfa053997b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "  X, y, test_size=1000, random_state=123, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092bccca",
   "metadata": {},
   "source": [
    "Convert training and validation arrays into DataFrames with proper column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1caf11ba-8d5d-4c97-b6f0-eaee087813b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train, columns = X.columns)\n",
    "y_train_df = pd.DataFrame(y_train, columns = ['label'])\n",
    "\n",
    "X_val_df = pd.DataFrame(X_val, columns = X.columns)\n",
    "y_val_df = pd.DataFrame(y_val, columns = ['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30652db",
   "metadata": {},
   "source": [
    "Combine labels and features into single DataFrames for training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ff16bdf-1485-4811-9ecc-c6314d760db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([y_train_df, X_train_df], axis=1)\n",
    "val_df = pd.concat([y_val_df, X_val_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc66aee",
   "metadata": {},
   "source": [
    "Save processed datasets for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b369fdcd-eaf0-4102-b0d3-5f796ec6200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"data/processed/train.csv\", index=False)\n",
    "val_df.to_csv(\"data/processed/validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93247bea",
   "metadata": {},
   "source": [
    "Convert datasets to JAX arrays for NumPyro compatibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "101e2374-31a8-477b-aba6-f6daeb870917",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = jnp.array(X_train), jnp.array(X_val)\n",
    "y_train, y_val = jnp.array(y_train), jnp.array(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcbfc54",
   "metadata": {},
   "source": [
    "Define experimental configurations: network widths, prior means for precision, and inference methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50ff4b-ed92-4c7a-9cfb-ff3f1d2b7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = [5, 10, 14]\n",
    "precision_priors = [0.01, 0.1, 1.0]  \n",
    "inference_methods = ['mcmc', 'vi']\n",
    "vi_guides = {\n",
    "    'AutoDiag': AutoDiagonalNormal,\n",
    "    'AutoMult': AutoMultivariateNormal\n",
    "}\n",
    "mcmc_kernels = {\n",
    "    'NUTS': NUTS\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d391f8",
   "metadata": {},
   "source": [
    "Map prior precision values to corresponding Gamma distribution parameters (alpha, beta):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bff7cd-c7ea-4d41-8ae3-7dc25b394dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_prior_map = {\n",
    "    0.01: (2.0, 200.0),  \n",
    "    0.1: (2.0, 20.0),   \n",
    "    1.0: (2.0, 2.0)   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88fba4a",
   "metadata": {},
   "source": [
    "Define BNN model with one hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa15813-bcc5-465d-99e4-525e79b11e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bnn_model(X, y=None, hidden_dim=10, precision_prior=1.0):\n",
    "    n, m = X.shape\n",
    "    alpha, beta = precision_prior_map[precision_prior]\n",
    "    precision_nn = numpyro.sample('precision_nn', dist.Gamma(alpha, beta))\n",
    "\n",
    "    # First layer: biases and weights\n",
    "    with numpyro.plate('l1_hidden', hidden_dim):\n",
    "        b1 = numpyro.sample(\n",
    "            'nn_b1', dist.Normal(0.0, jnp.sqrt(1.0 / (precision_nn*m)))\n",
    "        )\n",
    "        with numpyro.plate('l1_feat', m):\n",
    "            w1 = numpyro.sample(\n",
    "                'nn_w1', dist.Normal(0.0, jnp.sqrt(1.0 / (precision_nn*m)))\n",
    "            )\n",
    "\n",
    "    # Second (output) layer: weights and bias\n",
    "    with numpyro.plate('l2_hidden', hidden_dim):\n",
    "        w2 = numpyro.sample(\n",
    "            'nn_w2', dist.Normal(0.0, jnp.sqrt(1.0 / (precision_nn*hidden_dim)))\n",
    "        )\n",
    "    b2 = numpyro.sample(\n",
    "        'nn_b2', dist.Normal(0.0, jnp.sqrt(1.0 / (precision_nn*hidden_dim)))\n",
    "    )\n",
    "\n",
    "    # Forward pass with ReLU activation\n",
    "    hidden = jnp.maximum(X @ w1 + b1, 0)\n",
    "    logits = hidden @ w2 + b2\n",
    "\n",
    "    # Bernoulli likelihood\n",
    "    with numpyro.plate('data', n):\n",
    "        numpyro.sample('obs', dist.Bernoulli(logits=logits), obs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa28854b",
   "metadata": {},
   "source": [
    "Create output directories for results, ELBO values, and extra diagnostics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b823a5c-56f7-4d86-ba12-095cc7359945",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('results/bnn/', exist_ok=True)\n",
    "os.makedirs('results/bnn/elbo/', exist_ok=True)\n",
    "os.makedirs('results/bnn/extra/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8745be0f",
   "metadata": {},
   "source": [
    "Initialise experiment tracking variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d544d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_logs = []\n",
    "mcmc_chains = 2\n",
    "main_key = random.PRNGKey(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177d16e3",
   "metadata": {},
   "source": [
    "Main experiment loop over inference methods and configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295bd071-7e20-4050-a8d3-f6216ab73e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mcmc_NUTS_w5_s0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcbc80f20dc4061956dc183e9af7a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d079698afc7471184fe49b3ee65bd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mcmc_NUTS_w5_s1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece7467cc51149fab4bc6722f0420d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb229667a0e147208564c79265118cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mcmc_NUTS_w5_s2.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e938512dd3c4b4d9cdcf9d056fe9cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569578c256bd47399126324e3748de88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mcmc_NUTS_w10_s0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6676ae87ffeb4dfeab312851fb8712a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b97be0f017940c9a8dddacaadc0bd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mcmc_NUTS_w10_s1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da7b20f256d49c2b470512db8e2439a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d2b8aa94a44fb98e4afe7498c416ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for method in inference_methods:\n",
    "    if method == 'mcmc':\n",
    "\n",
    "        # Loop over MCMC kernels (just NUTS)\n",
    "        for kernel_name, kernel_cls in mcmc_kernels.items():\n",
    "            for width in widths:\n",
    "                for prior in precision_priors:\n",
    "                    id = f'{method}_{kernel_name}_w{width}_p{prior:.3g}'\n",
    "                    print(f'Running {id}')\n",
    "                    \n",
    "                    # Generate independent PRNG keys for each MCMC chain\n",
    "                    main_key, run_key = random.split(main_key)\n",
    "                    chain_keys = random.split(run_key, num=mcmc_chains)\n",
    "                    \n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    try:\n",
    "                        # Initialise and run MCMC\n",
    "                        kernel = kernel_cls(\n",
    "                            bnn_model, init_strategy=init_to_mean\n",
    "                        )\n",
    "                        mcmc = MCMC(\n",
    "                            kernel, num_warmup=100, num_samples=250, \n",
    "                            num_chains=mcmc_chains\n",
    "                        )\n",
    "                        mcmc.run(\n",
    "                            chain_keys, X_train, y_train, hidden_dim=width, \n",
    "                            precision_prior=prior\n",
    "                        )\n",
    "                        results = mcmc.get_samples(group_by_chain=True)\n",
    "                        \n",
    "                        # Save posterior samples and extra diagnostics\n",
    "                        with open(f'results/bnn/{id}_samples.pkl', 'wb') as f:\n",
    "                            pickle.dump(results, f)\n",
    "\n",
    "                        extras = mcmc.get_extra_fields()\n",
    "                        with open(f'results/bnn/extra/{id}_extra.pkl', 'wb') as f:\n",
    "                            pickle.dump(extras, f)\n",
    "                        \n",
    "                        # Log experiment success\n",
    "                        duration = time.time() - start_time\n",
    "                        experiment_logs.append({\n",
    "                            'id': id,\n",
    "                            'method': method,\n",
    "                            'kernel': kernel_name,\n",
    "                            'width': width,\n",
    "                            'precision_prior': prior,\n",
    "                            'duration_seconds': round(duration, 2),\n",
    "                            'status': 'success'\n",
    "                        })\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        # Log experiment failure\n",
    "                        duration = time.time() - start_time\n",
    "                        experiment_logs.append({\n",
    "                            'id': id,\n",
    "                            'method': method,\n",
    "                            'kernel': kernel_name,\n",
    "                            'width': width,\n",
    "                            'precision_prior': prior,\n",
    "                            'duration_seconds': round(duration, 2),\n",
    "                            'status': f'error: {str(e)}'\n",
    "                        })\n",
    "                        print(f'Experiment {id} failed: {e}')\n",
    "\n",
    "    else:  # Variational inference branch\n",
    "\n",
    "        # Loop over VI guide types\n",
    "        for guide_name, guide_cls in vi_guides.items():\n",
    "            for width in widths:\n",
    "                for prior in precision_priors:\n",
    "                    \n",
    "                    id = f'{method}_{guide_name}_w{width}_p{prior:.3g}'\n",
    "                    print(f'Running {id}')\n",
    "                    \n",
    "                    # Generate PRNG keys for training and posterior sampling\n",
    "                    main_key, run_key, post_key = random.split(main_key, 3)\n",
    "                    \n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    try:\n",
    "                        # Initialise and run SVI\n",
    "                        guide = guide_cls(bnn_model)\n",
    "                        svi = SVI(\n",
    "                            bnn_model, guide, numpyro.optim.Adam(1e-3), \n",
    "                            Trace_ELBO()\n",
    "                        )\n",
    "                        svi_result = svi.run(\n",
    "                            run_key, 2000, X_train, y_train, hidden_dim=width, \n",
    "                            precision_prior=prior\n",
    "                        )\n",
    "\n",
    "                        # Save ELBO trajectory\n",
    "                        elbo_vals = svi_result.losses\n",
    "                        \n",
    "                        # Draw posterior samples from the fitted guide\n",
    "                        results = guide.sample_posterior(\n",
    "                            post_key, svi_result.params, sample_shape=(500,)\n",
    "                        )\n",
    "                        \n",
    "                        # Save posterior samples and ELBO values\n",
    "                        with open(f'results/bnn/{id}_samples.pkl', 'wb') as f:\n",
    "                            pickle.dump(results, f)\n",
    "\n",
    "                        with open(f'results/bnn/elbo/{id}_elbo.pkl', 'wb') as f:\n",
    "                            pickle.dump(elbo_vals, f)\n",
    "                        \n",
    "                        # Log experiment success\n",
    "                        duration = time.time() - start_time\n",
    "                        experiment_logs.append({\n",
    "                            'id': id,\n",
    "                            'method': method,\n",
    "                            'guide': guide_name,\n",
    "                            'width': width,\n",
    "                            'precision_prior': prior,\n",
    "                            'duration_seconds': round(duration, 2),\n",
    "                            'status': 'success'\n",
    "                        })\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        # Log experiment failure\n",
    "                        duration = time.time() - start_time\n",
    "                        experiment_logs.append({\n",
    "                            'id': id,\n",
    "                            'method': method,\n",
    "                            'guide': guide_name,\n",
    "                            'width': width,\n",
    "                            'precision_prior': prior,\n",
    "                            'duration_seconds': round(duration, 2),\n",
    "                            'status': f'error: {str(e)}'\n",
    "                        })\n",
    "                        print(f'Experiment {id} failed: {e}')\n",
    "\n",
    "# Save experiment log to CSV\n",
    "log_df = pd.DataFrame(experiment_logs)\n",
    "log_df.to_csv('results/experiment_log.csv', index=False)\n",
    "print('Experiment summary saved to results/experiment_log.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybersec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
