# Methods {sec-methods}

## The UNSW-NB15 Network Dataset

The UNSW-NB15 dataset [@moustafa2015unsw; @moustafa2016evaluation] was created to overcome the limitations of earlier benchmark datasets such as KDD99 and NSL-KDD, which have been criticised for outdated attack types, unrealistic normal traffic, and inconsistent distributions between training and testing sets. In contrast, UNSW-NB15 combines modern real-world network activity with synthetically generated attack behaviours, making it highly suitable for evaluating contemporary Network Intrusion Detection Systems (NIDSs). The dataset contains 49 features encompassing both flow-level host interactions and deep packet inspection metrics, enabling effective discrimination between normal and malicious traffic. It includes nine categories of contemporary cyberattacks alongside updated profiles of normal network behaviour. Statistically, UNSW-NB15 is more complex than its predecessors [@moustafa2016evaluation].

The full dataset comprises 2,540,044 records, of which 2,218,761 (approximately 87%) correspond to normal traffic, resulting in a highly imbalanced class distribution that reflects real-world network conditions [@zoghi2021unsw]. The training and testing subsets were obtained directly from the [UNSW website](https://research.unsw.edu.au/projects/unsw-nb15-dataset) [@unsw2015nb15], consisting of 175,341 and 82,332 records, respectively. Statistical analysis has demonstrated that the training and test sets share similar non-linear and non-normal feature distributions. Furthermore, high statistical correlation between the two sets supports their appropriateness as benchmark data for evaluating statistical and machine learning models tasked with distinguishing complex attack patterns from normal traffic [@moustafa2016evaluation]. Non-informative features were excluded from the distributed datasets, yielding a total of 42 usable predictors and two target variables: `label` (binary attack indicator) and `attack_cat` (attack category), as described in @supptbl-dict.

An initial examination of the training dataset revealed that it contains a disproportionate number of attack records (68.06%) compared to normal traffic (31.93%), which does not reflect realistic conditions. To create a more representative imbalanced subset for our analysis, we retained only the normal traffic and denial-of-service (DoS) attack instances. This resulted in a subset with 82.03% normal and 17.97% DoS traffic, closely aligning with the class distribution in the full dataset.

## Feature Engineering

Exploratory data analysis was conducted to assess the quality and distribution of the features. One of the first issues identified was with the features `is_ftp_login` and `ct_ftp_cmd`, which were found to be identical in the training dataset and contained integer values ranging from 0 to 4. This was unexpected, as `is_ftp_login` is defined as a binary variable in the data dictionary, suggesting possible data corruption. Given that the observed values appeared to align with the definition of `ct_ftp_cmd`, we chose to drop `is_ftp_login` from the training set. Interestingly, this anomaly was not observed in the test set, where the two features differed as expected.

The nominal features `proto`, `service`, and `state` had 133, 13, and 9 unique levels, respectively. However, only a small subset of these levels accounted for the vast majority of records in the training data. To reduce dimensionality and improve model interpretability, we grouped the infrequent levels in each feature into a single "other" category. We applied a Pareto principle approach, retaining the levels that together covered approximately 90% of the records. After grouping, `proto` was reduced to 5 levels, `service` to 4, and `state` to 4, resulting in a more manageable set of categories for downstream modelling.

Most numeric features exhibited strong right-skewness, with a pronounced peak at zero, likely indicating unsuccessful or dropped connections. Further inspection revealed that several variables take values from a limited set of predefined ranges. For example, `sttl` and `dttl`, which represent source and destination time-to-live (TTL) values, frequently appeared near 0, 30, 60, and 250. According to @ttl, typical initial TTL values are 64, 128, and 255, which gradually decrease during transmission—consistent with the observed values, along with the additional cluster near 30. As these values reflect discrete categories rather than continuous magnitudes, we recoded them as ordinal variables with levels "0", "~30", "~64", and "~255". Similarly, the features `swin` and `dwin` predominantly took values of 0 and 255, with other values appearing very infrequently (often only once). This pattern suggested that 0 and 255 may also be predefined values. Accordingly, we discretised these numeric features into the nominal levels "0", "255", and "rare".

Before feature selection and model building, nominal features were one-hot encoded, ordinal features were mapped to integers, and numeric features were log-transformed and scaled using a robust scaler. The robust scaler subtracts the median and divides by the interquartile range (IQR), making it more suitable for highly skewed data than standard scaling, which assumes a roughly symmetric distribution. Because most numeric features were heavily skewed and included zero values, we explored various log-based transformations. For features with zeros, we tested log transformations with two offsets: adding 1, and adding half the smallest non-zero value, as suggested by @hyndman2013transformations. We also tested the Yeo–Johnson transformation. Visual inspection showed that the latter offset approach provided the best normalisation, so we applied it to features containing zeros, while using the standard log transformation for strictly positive features.

## Feature Selection

To reduce redundancy and retain the most informative features, we applied a two-stage feature selection strategy combining correlation analysis and model-based permutation importance.

First, after preprocessing (see earlier section), we computed the Spearman correlation matrix for the numeric features in the training set. Feature pairs with a high correlation (≥ 0.9) were flagged, and for each pair, we retained the feature with the higher mutual information (MI) score relative to the binary target variable. MI measures the amount of shared information between two variables, capturing any form of statistical dependency—beyond linear correlation—and is particularly well-suited for assessing relationships between a discrete and a continuous variable [@ross2014mutual]. MI was estimated using a nearest-neighbour-based method, which avoids the resolution loss associated with binning and provides a more accurate, non-parametric measure of association [@ross2014mutual, @sklearn-mi]. This filtering step helped reduce redundancy while preserving features most informative for the classification task.

In the second stage, we employed a random forest (RF) classifier to assess feature relevance using permutation importance. The training data was split into a sub-training and validation set using stratified sampling to preserve the class distribution, allocating 20% of the data for validation. A model was then trained using a grid search with 5-fold stratified cross-validation, optimising the F1 score. Although this was not the final predictive model, we carefully selected the hyperparameter grid to reduce overfitting. Specifically, we tuned the number of trees ({1000, 1500}), maximum tree depth ({3, 5}), and minimum number of samples required to split an internal node ({10, 15}) [@sklearn-rfclassifier]. In addition, we addressed class imbalance by applying class weights in the learning algorithm, using the "balanced" scheme, which assigns weights inversely proportional to class frequencies [@sklearn-rfclassifier]. After selecting the best-performing model, permutation importance was computed on the validation set by measuring the average decrease in F1 score when each feature was randomly shuffled across 10 repetitions. To further simplify the feature space, we grouped the importance scores of one-hot encoded variables by their original categorical variable (e.g., all `proto_*` columns were aggregated under `proto`). We then selected the top ten base features and retained all corresponding encoded columns, yielding a compact and interpretable set of predictors for subsequent modelling.

## Bayesian Neural Networks (BNNs)

### Neural Networks (NNs)

Neural networks (NNs) are hierarchical models composed of an input layer, one or more hidden layers, and an output layer, where each layer consists of units that perform a linear transformation followed by a non-linear activation function [@arbel2023primer]. Training a neural network involves finding the set of weights and biases at the hidden and output layers that minimise a specified loss function, typically using gradient-based optimisation algorithms, such as stochastic gradient descent (SGD), and backpropagation [@jospin2022hands].

Formally, given an input vector $\mathbf{x} \in \mathbb{R}^n$, a neural network with $L$ hidden layers of widths $H_1, \dots, H_L$, and a non-linear activation function $\phi: \mathbb{R} \rightarrow \mathbb{R}$, the computations at layer $l$ ($l = 1, \dots, L$) are:

$$
\begin{aligned}
\mathbf{g}^{(l)}(\mathbf{x}) &= \mathbf{w}^{(l)} \mathbf{h}^{(l-1)}(\mathbf{x}) + \mathbf{b}^{(l)} \\
\mathbf{h}^{(l)}(\mathbf{x}) &= \phi\left(\mathbf{g}^{(l)}(\mathbf{x})\right),
\end{aligned}
$$

where $\mathbf{w}^{(l)}$ is the weight matrix of dimensions $H_l \times H_{l-1}$, $\mathbf{b}^{(l)}$ is a bias vector of length $H_l$, $\mathbf{h}^{(l-1)}(\mathbf{x})$ denotes the post-activation values of the previous layer (with $\mathbf{h}^{(0)} = \mathbf{x}$), and $\mathbf{g}^{(l)}(\mathbf{x})$ are the pre-activation values. For the output layer, the pre-activation value is $g^{(L+1)}(\mathbf{x}) = \mathbf{w}^{(L+1)} \mathbf{h}^{(L)}(\mathbf{x}) + b^{(L+1)}$, where, in the binary classification setting, $\mathbf{w}^{(L+1)} \in \mathbb{R}^{H_L}$ is the weight vector connecting the last hidden layer to the single output neuron, and $b^{(L+1)} \in \mathbb{R}$ is the scalar bias. The output-layer activation function is selected to match the target variable’s distribution; for example, the sigmoid function is used for a Bernoulli-distributed binary outcome $y \in \{0,1\}$. While $\phi$ is often fixed across layers, it may vary depending on the network architecture or specific application [@arbel2023primer]. Some popular choices are the hyperbolic tangent function (tanh), the rectified linear unit (ReLU) function, and the softmax function for multi-class classification tasks.

A widely used loss function for binary classification is the binary cross-entropy (BCE), also known as log loss. Let $\theta$ denote the set of all parameters (weights and biases) in the neural network, and let $f(\mathbf{x}_i; \theta)$ represent the predicted probability output by the network for input $\mathbf{x}_i$. Given a dataset $\{(\mathbf{x}_i, y_i)\}_{i=1}^N$, where $y_i \in \{0,1\}$, the BCE is defined as

$$
J(\theta) = -\sum_{i=1}^N \big[ y_i \log f(\mathbf{x}_i; \theta) + (1-y_i) \log \big( 1 - f(\mathbf{x}_i; \theta) \big) \big].
$$

Training a NN for binary classification therefore amounts to finding the set of parameters $\hat{\theta}$ that minimises this loss:

$$
\hat{\theta} = \underset{\mathbf{w}}{\mathrm{arg\,min}} \; J(\mathbf{w}).
$$

This optimisation is typically performed using SGD, where gradients are estimated at each iteration using randomly selected subsets of the data, known as mini-batches [@arbel2023primer]. Because the optimiser does not need to process the entire dataset at each step, but only a small random portion of it, SGD is particularly well suited for large-scale datasets. Another widely used stochastic optimiser is Adam (adaptive moment estimation), which extends SGD by incorporating adaptive learning rates and momentum terms. Adam is computationally efficient, requires minimal memory, and often converges faster in practice [@adam2014method].

This setup is equivalent to finding the maximum likelihood estimates (MLE) of $\theta$ [@goodfellow2016deep]. Since the parameters are treated as fixed quantities, this corresponds to a frequentist approach to training NNs. Under this traditional framework, NNs have demonstrated remarkable performance across a wide range of challenging tasks, including object recognition, speech recognition, and natural language understanding [@jospin2022hands]. Their success stems from a combination of factors: high expressive power due to their complexity and over-parameterisation; beneficial inductive biases introduced through architectural design; and flexibility to mitigate overfitting via explicit and implicit regularisation techniques [@arbel2023primer]. Together, these characteristics enable NNs to achieve strong generalisation in diverse application domains. 

### The Bayesian Approach

However, the frequentist approach to neural networks presents important limitations, particularly in safety-critical real-world applications such as medical diagnosis and cyber-security [@arbel2023primer]. In particular, neural networks often produce miscalibrated or overconfident predicted class probabilities in classification tasks, are sensitive to out-of-distribution samples and domain shifts, are vulnerable to adversarial attacks, lack inherent human interpretability (often functioning as “black-box” models), and may generalise poorly when data is limited [@arbel2023primer; @jospin2022hands]. A variety of strategies have been proposed to address these issues, with Bayesian neural networks (BNNs) standing out as one of the most rigorous and conceptually intuitive frameworks for building robust, uncertainty-aware models [@jospin2022hands].

BNNs differ from their frequentist counterparts in that the parameters $\theta \in \Theta$ are treated as random variables endowed with a prior distribution $p(\theta)$. Given a dataset $D = \{(\mathbf{x}_i, y_i)\}_{i=1}^N$ and a likelihood function $p(D | \theta)$ describing how the parameters generate the observed data, the Bayesian approach seeks to infer the posterior distribution

$$
p(\theta | D) = \frac{p(D | \theta)\, p(\theta)}{p(D)} \propto p(D | \theta)\, p(\theta).
$$

For NNs, however, this posterior is typically a high-dimensional, highly non-convex probability distribution [@jospin2022hands]. Moreover, computing it exactly requires evaluating the evidence

$$
p(D) = \int_{\Theta} p(D | \theta)\, p(\theta) \, d\theta,
$$

an integral over a vast and non-linear parameter space. This calculation is analytically intractable and computationally prohibitive, even for moderately sized networks. Consequently, to estimate the posterior, BNNs rely on sampling methods such as Markov chain Monte Carlo (MCMC) or approximation methods such as variational inference (VI) [@jospin2022hands].

Given $p(\theta | D)$, the posterior predictive distribution for a new observation $y^{*}$ associated with some input $\mathbf{x}^{*}$, $p(y^{*} | \mathbf{x}^{*}, D)$, is given by

$$
p(y^{*} | \mathbf{x}^{*}, D) = \mathbb{E}\!\left[p(y^{*} | \mathbf{x}^{*}, \theta) | D\right] 
= \int_{\mathbfcal{W}} p(y^{*} | \mathbf{x}^{*}, \theta) \, p(\theta | D) \, d\theta.
$$

In practice, direct evaluation of this integral is intractable, so it is commonly approximated by drawing samples $\theta^{(s)} \sim p(\theta | D)$ and computing the corresponding likelihood terms $p(y^{*} | \mathbf{x}^{*}, \theta^{(s)})$. These values are then averaged using a Monte Carlo estimator, yielding an empirical approximation of the posterior predictive distribution [@jospin2022hands]. This process naturally incorporates epistemic uncertainty (uncertainty in the model parameters) by marginalising over the posterior $p(\theta | D)$. This type of uncertainty is distinct from aleatoric uncertainty, which stems from inherent noise in the data and cannot be reduced by collecting additional observations [@jospin2022hands; @arbel2023primer].

BNNs provide a principled approach to uncertainty quantification by explicitly modelling the posterior over the network parameters. This yields better-calibrated predictions than conventional NNs, where predicted probabilities more accurately reflect empirical frequencies, thereby reducing both overconfidence and underconfidence [@jospin2022hands]. By disentangle epistemic from aleatoric uncertainty, BNNs also exhibit improved robustness: for out-of-distribution samples, they express high epistemic uncertainty rather than unjustified confidence [@jospin2022hands].

Beyond uncertainty quantification, BNNs offer a coherent framework for incorporating prior knowledge into neural networks as inductive bias, making explicit what is often only implicit in other learning algorithms [@jospin2022hands]. Priors can act as soft constraints, analogous to regularisation, and many established deep neural network techniques, such as ensembling or data augmentation, can be interpreted through a Bayesian lens. This perspective not only deepens theoretical understanding but also provides a systematic basis for developing new learning strategies, even when exact Bayesian inference is computationally infeasible [@jospin2022hands].

### Priors

**PRIORs, why are they difficult in BNN, equivalences with regularization** A primer and What are


### Inference Methods

#### Markov Chain Monte Carlo (MCMC)

Markov Chain Monte Carlo (MCMC) methods approximate the posterior distribution of BNN parameters by constructing a Markov chain whose stationary distribution matches the desired posterior [@jospin2022hands]. While conceptually straightforward, applying MCMC to BNNs is computationally challenging due to the high dimensionality of the parameter space and the strong correlations between parameters[@jospin2022hands]. While generic MCMC algorithms like Gibbs sampling are ill-suited to BNNs, the Metropolis–Hastings (MH) algorithm is more applicable, as it requires to evaluate only a function proportional to the posterior, effectively avoiding the evaluation of its normalising constant [@jospin2022hands]. 

The MH algorithm requires the user to chose a proposal distribution $Q(\theta^{*}|\theta)$ from which candidate samples $\theta^{*}$ for the target posterior distribution are drawn. Given a target posterior distribution $p(\theta|D) \propto p(D|\theta)p(\theta)$ and denoting $f(\theta)=p(D|\theta)p(\theta)$, the MH algorithm generates a set of samples (i.e., a Markov chain) $\{\theta^{(t)}\}_{t=1}^T$ as follows:

1. Set initial values $\theta^{(0)}$
2. For $t = 0, \dots, T-1$ do:
    - Given the current state $\theta^{(t)}=\theta$, draw a candidate $\theta^{*} \sim Q(\theta^{*} | \theta)$.
    - Compute the acceptance probability:
    $$
    \gamma = \min\left(1, \frac{f(\theta^{*})Q(\theta|\theta^{*})}{f(\theta)Q(\theta^{*}|\theta)}\right).
    $$
    - Draw $u \sim \mathcal{U}(0,1)$.
    - If $u \leq \gamma$, accept the candidate and set $\theta^{(t+1)}=\theta^{*}$, else set $\theta^{(t+1)}=\theta$.

**Explain a little bit how MCMC works, warm-up and diagnostics**

Hamiltonian Monte Carlo (HMC) [@neal2011mcmc] improves the efficiency of the MH algorithm by leveraging gradient information to guide proposals along trajectories that better explore the posterior, reducing random-walk behaviour and improving mixing in high dimensions [@hoffman2014no]. However, HMC’s performance depends on careful tuning of the step size and the number of leapfrog steps, which can be difficult in practice. The No-U-Turn Sampler (NUTS) [@hoffman2014no] extends HMC by removing the need to predefine the trajectory length. It adaptively stops simulating the Hamiltonian dynamics when the trajectory begins to double back on itself, avoiding inefficient exploration [@hoffman2014no]. NUTS also uses a primal–dual averaging scheme to automatically tune the step size, making it a robust and largely hand-free MCMC method [@hoffman2014no]. These features make NUTS particularly well-suited for BNNs, where efficient sampling in high-dimensional, multimodal posteriors is crucial.

#### Variational Inference (VI)

While MCMC methods provide exact samples from the posterior, their limited scalability has shifted focus towards variational inference (VI) as a more computationally efficient alternative for Bayesian neural networks (BNNs). VI approximates the true posterior $p(\theta | D)$ with a variational distribution $q_{\phi}(\theta)$, parameterized by $\phi$ (i.e., parameters such as location, scale, etc.). This variational distribution is optimised to minimize the Kullback-Leibler (KL) divergence between the two distributions, which is a measure of distance between the distributions [@jospin2022hands]. Denoting $q_{\phi}=q$, the KL divergence is given by:

$$
\begin{aligned}
\text{KL}\left(q \mid \mid p(\theta, D)\right)&=\int_{\Theta}{q(\theta)\text{log}\left(\frac{q(\theta)}{p(\theta|D)}\right)d\theta} \\
&=-\int_{\Theta}{q(\theta)\text{log}\left(\frac{p(\theta)p(D|\theta)}{q(\theta)}\right)d\theta}+\text{log}p(D)
\end{aligned}
$$

Given that the $\text{log}p(D)$ does not depend on the choice of $q$, minimising the KL divergence is equivalent to minimising the first term, which is called the evidence lower bound (ELBO):

$$
\begin{aligned}
\text{ELBO}(q)&=\int_{\Theta}{q(\theta)\text{log}\left(\frac{p(\theta)p(D|\theta)}{q(\theta)}\right)d\theta} \\
&=\int_{\Theta}{q(\theta)\text{log}p(D|\theta)d\theta}-\text{KL}\left(q \mid \mid p(\theta)\right) \\
&=\text{E}\left(\text{log}p(D|\theta)\right)-\text{KL}\left(q \mid \mid p(\theta)\right)
\end{aligned}
$$

The first component represents the expected likelihood, promoting a distribution $q$ that effectively account for the observed data. The second component corresponds to the negative KL divergence between $q$ and the prior, encouraging the variational distribution to remain close to the prior. Together, these terms reflect the balance between likelihood and prior [@blei2017variational]. The ELBO can be efficiently optimized using stochastic gradient descent (SGD) or Adam optimizers, enabling scalability to large datasets [@jospin2022hands]. Distributions from the exponential family, particularly Gaussian distributions, are popular choices for the variational distribution $q$ due to their mathematical convenience and tractability [@jospin2022hands].

Several widely used VI algorithms for BNNs, including Bayes-by-Backprop [@blundell2015weight] and probabilistic backpropagation [@hernandez2015probabilistic], rely on the mean-field assumption, which treats network parameters $\theta_k$ as mutually independent each governed by distinct factor $q_{k}(\theta_k)$ in the variational distribution [@blei2017variational]:

$$
q(\theta)=\prod_{m=1}^{M}{q_{k}(\theta_k)},
$$

where $M$ is the total number of parameters in the neural network. Although this assumption simplifies computation and facilitates scalable inference, it is often overly restrictive and can lead to underestimated uncertainty by ignoring dependencies among parameters [@arbel2023primer]. More expressive variational distributions, such as full-covariance multivariate Gaussians, aim to mitigate these limitations. Nonetheless, VI methods are known to suffer from mode collapse, focusing on a single mode of the posterior despite the multimodal nature commonly observed in BNN posteriors [@arbel2023primer]. Consequently, achieving accurate variational approximations in deep neural networks remains challenging and typically requires careful hyperparameter tuning [@arbel2023primer].

## Benchmarking 

We evaluated the performance of BNNs with different configurations for detecting DoS cyber-attacks using the UNSW-NB15 dataset. Model performance was assessed using precision, recall, and the $F_1$ score. Precision measures the proportion of correctly identified attacks among all instances predicted as attacks, while recall measures the proportion of correctly identified attacks among all actual attacks. The $F_1$ score, the harmonic mean of precision and recall, provides a single metric that balances both aspects. All three metrics take values in $[0,1]$, with values closer to 1 indicating better performance.

BNNs with a single hidden layer ($L = 1$) and ReLU activations were trained under multiple configurations and evaluated on a validation set of 1,000 samples randomly drawn from the training data. Although precision, recall, and $F_1$ scores were computed on the validation set, BNN model selection was based solely on the $F_1$ score. The selected BNN was compared against (i) a frequentist neural network with identical architecture but without parameter priors, and (ii) a gradient-boosted decision tree (GBDT), which is a strong baseline for classification tasks, particularly on tabular data.

BNNs were implemented in NumPyro [@phan2019composable; @bingham2019pyro], a probabilistic programming library for Python. In NumPyro, variational distributions are referred to as guides, and we adopt this terminology here. The BNN configurations differed in:

1. Hidden layer width ($H_1$): 5, 10, and 14 (equal to the number of input features).
2. Prior precision: prior mean precisions of 0.5, 1, and 2.
3. Inference method: Markov Chain Monte Carlo (MCMC) using the No-U-Turn Sampler (NUTS) vs. Variational Inference (VI).
4. Guide type (VI only): mean-field Gaussian and multivariate Gaussian.

The hidden layer widths were chosen to reflect different model complexities, approximately corresponding to one-third, two-thirds, and the full input dimension. A zero-mean Gaussian prior was placed on all network parameters $\theta$, assumed independent and identically distributed (i.i.d.). The prior variances followed the He initialisation scaling [@he2015delving], which is particularly effective for ReLU activations. Specifically, for the hidden layer weights and biases:

$$
w_{ij}^{(1)} \sim \mathcal{N}\left(0, \frac{2}{14 \tau}\right) \quad \text{and} \quad b_{i}^{(1)} \sim \mathcal{N}\left(0, \frac{2}{14 \tau}\right),
$$

for $i = 1, \ldots, 14$ (input dimension) and $j = 1, \ldots, H_1$ ($H_1 \in \{5, 10, 14\}$).

For the output layer pre-activations:

$$
w_{j}^{(2)} \sim \mathcal{N}\left(0, \frac{2}{\tau H_1}\right) \quad \text{and} \quad b^{(2)} \sim \mathcal{N}\left(0, \frac{2}{\tau H_1}\right),
$$

for $j = 1, \ldots, H_1$.

Here, $\tau$ is a precision-like parameter controlling the scaling of the Gaussian distributions (not strictly the variance inverse). A Gamma prior was placed on $\tau$, with shape $\alpha$ and rate $\beta$ chosen to yield prior mean precisions of 0.5 ($\alpha=1,\ \beta=2$), 1 ($\alpha=6,\ \beta=6$), or 2 ($\alpha=4,\ \beta=2$).

Denote the training dataset as $\{(\mathbf{x}_i, y_i)\}_{i=1}^{N}$, where $N=67{,}264$. The outputs $y_i$ ($i=1,\ldots,N$), were assumed Bernoulli-distributed with probability of attack $p_i$ and a sigmoid activation through a logit function:

$$
\begin{aligned}
y_i &= \mathcal{B}(p_i) \\
\text{logit}(p_i) &= \text{log}\left(\frac{p_i}{1-p_i}\right) = \mathbf{w}^{(2)}\mathbf{h}^{(1)}(\mathbf{x}_i) + b^{(2)},
\end{aligned}
$$

where $\mathbf{x}_i$ is the input vector for sample $i$ and $\mathbf{h}^{(1)}(\mathbf{x}_i)$ is the hidden layer output. The training dataset is denoted .

For MCMC, the NUTS algorithm was run with two chains, each generating 500 post-warm-up samples after 250 warm-up iterations. Parameters were initialised at their prior means, and all other settings used NumPyro defaults (target acceptance probability $\gamma=0.8$). Summary statistics and convergence diagnostics were computed for each parameter, including posterior mean, standard deviation, median, highest posterior density interval (HPDI), ESS, and the $\hat{R}$ statistic.

For VI, both mean-field and multivariate Gaussian guides were created using NumPyro’s automatic guide generation. Guides were initialised with means randomly chosen from a uniform distribution with support $[-2, 2]$ and standard deviations of 0.1 (default options). The multivariate Gaussian guide was initialised as a diagonal Gaussian (no correlations), but unlike the mean-field guide, it could learn correlations during optimisation. The Adam optimiser with a defaul learning rate of $10^{-3}$ ELBO trace plots were monitored to verify convergence, with convergence indicated by a plateau in the ELBO curve. 






## Interpretability Analysis

